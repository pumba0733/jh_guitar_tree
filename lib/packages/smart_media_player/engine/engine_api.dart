// lib/packages/smart_media_player/engine/engine_api.dart
//
// SmartMediaPlayer v3.8-FF â€” STEP 4 + Step 3-P2/P3 StartCue/Loop/Space/FFRW í†µí•©
// EngineApi = FFmpeg ë„¤ì´í‹°ë¸Œ ì—”ì§„ thin wrapper + mpv(video-only)
//
// ì±…ì„:
//  - íŒŒì¼ ë¡œë“œ(FFmpeg ë„¤ì´í‹°ë¸Œ ì—”ì§„ openFile)
//  - play/pause/seekUnified
//  - tempo/pitch/volume (ë„¤ì´í‹°ë¸Œ ì—”ì§„)
//  - spaceBehavior / playFromStartCue / loopExitToStartCue
//  - unified seek (audio master, video slave)
//  - video sync ë³´ì¡° (VideoSyncServiceì— pending target ì œê³µ)
//  - position/duration stream (FFmpeg SoT ê¸°ë°˜)
//  - FFRW (seek ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜)
//
// ì œì•½:
//  - ì˜¤ë””ì˜¤ëŠ” 100% ë„¤ì´í‹°ë¸Œ ì—”ì§„ì´ ë‹´ë‹¹ (FFmpeg + SoundTouch + miniaudio)
//  - media_kit PlayerëŠ” ì˜ìƒ ë Œë”ë§ ë° ì™„ë£Œ ì´ë²¤íŠ¸ ì „ìš©
//

import '../../smart_media_player/video/sticky_video_overlay.dart';
import 'dart:async';
import 'dart:io';

import 'package:flutter/material.dart';
import 'package:media_kit/media_kit.dart';
import 'package:media_kit_video/media_kit_video.dart';

import '../audio/engine_soundtouch_ffi.dart';
import '../video/video_sync_service.dart';

// ================================================================
// SoT / Playback QA ë¡œê¹… í—¬í¼
// ================================================================

// âœ… ê¸°ë³¸ ì´ë²¤íŠ¸(ë¡œë“œ/í”Œë ˆì´/ì¼ì‹œì •ì§€/ì‹œí¬ ë“±) ë¡œê·¸
const bool kSmpEngineLogBasic = true;

// âœ… SoT tick / FFRW tick ê°™ì´ "ìì£¼ ì°íˆëŠ” ë¡œê·¸" ì „ìš© ìŠ¤ìœ„ì¹˜
//   â†’ í‰ì†Œì—ëŠ” falseë¡œ ë‘ê³ , QA ë• trueë¡œ ì˜¬ë ¤ì„œ ì“°ë©´ ë¨.
const bool kSmpEngineLogTick = false;

void _logSmpEngine(String message, {bool tick = false}) {
  if (tick) {
    if (!kSmpEngineLogTick) return;
  } else {
    if (!kSmpEngineLogBasic) return;
  }
  debugPrint('[SMP/EngineApi] $message');
}

class EngineApi {
  EngineApi._();
  static final EngineApi instance = EngineApi._();

  // ================================================================
  // CORE FIELDS
  // ================================================================
  final Player _player = Player(); // video ì „ìš©
  bool _initialized = false;
  bool _hasFile = false;

  Duration _duration = Duration.zero;

  /// StartCueì˜ ë‹¨ì¼ ì†ŒìŠ¤ (Screen ìƒíƒœì—ì„œ ì£¼ì…)
  /// - Screen ìª½ì—ì„œ `EngineApi.instance.startCueProvider = () => _startCue;`
  ///   í˜•íƒœë¡œ ì„¤ì •í•œë‹¤.
  Duration Function()? startCueProvider;

  // ë„¤ì´í‹°ë¸Œ ì—”ì§„ ì¬ìƒ ìƒíƒœ(ì˜¤ë””ì˜¤ ê¸°ì¤€)
  bool _nativePlaying = false;

  // SEEK LOCKING SYSTEM
  bool _seeking = false; // seekUnified() ì‹¤í–‰ ì¤‘ ë³´í˜¸ í”Œë˜ê·¸

  // VideoSyncServiceì—ì„œ ì†Œë¹„í•˜ëŠ” ë‹¨ì¼ pending íƒ€ê²Ÿ
  Duration? _pendingVideoTarget;

  // Streams
  final _positionCtl = StreamController<Duration>.broadcast();
  final _durationCtl = StreamController<Duration>.broadcast();
  final _playingCtl = StreamController<bool>.broadcast();

  Stream<Duration> get position$ => _positionCtl.stream;
  Stream<Duration> get duration$ => _durationCtl.stream;
  Stream<bool> get playing$ => _playingCtl.stream;

  // FFmpeg SoT pollingìš© íƒ€ì´ë¨¸
  Timer? _positionTimer;
  DateTime? _lastPosLogAt;

  // ğŸ”¥ ì˜¤ë””ì˜¤(FFmpeg SoT) ê¸°ì¤€ íŠ¸ë™ ì¢…ë£Œ ê°ì§€ìš© ìƒíƒœ
  Duration? _lastPolledPosition;
  bool _endCandidate = false;

  // ================================================================
  // PUBLIC GETTERS
  // ================================================================
  Player get player => _player; // UI read-only (video ì „ìš©)

  Duration get duration => _duration;

  /// FFmpeg SoT ê¸°ë°˜ í˜„ì¬ ìœ„ì¹˜ (í•­ìƒ [0, duration] ë²”ìœ„ë¡œ í´ë¨í”„)
  Duration get position {
    if (!_hasFile || _duration <= Duration.zero) return Duration.zero;
    final raw = stGetPosition();
    final pos = _clampToDuration(raw);
    return pos;
  }

  bool get isPlaying => _nativePlaying;

  // VideoSyncService bridge
  bool get hasVideo => VideoSyncService.instance.isVideoLoaded;
  Duration get videoPosition => VideoSyncService.instance.videoPosition;
  VideoController? get videoController => VideoSyncService.instance.controller;

  // VideoSyncService Phase E: ë‹¨ì¼ pendingVideoTarget ì±„ë„
  Duration? get pendingVideoTarget => _pendingVideoTarget;
  set pendingVideoTarget(Duration? v) => _pendingVideoTarget = v;

  // ğŸ” ê¸°ì¡´ ì´ë¦„ê³¼ì˜ í˜¸í™˜ìš©(ë‹¤ë¥¸ íŒŒì¼ì—ì„œ ì°¸ì¡° ì¤‘ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‚¨ê²¨ë‘ )
  @Deprecated('Use pendingVideoTarget instead')
  Duration? get pendingSeekTarget => _pendingVideoTarget;
  @Deprecated('Use pendingVideoTarget instead')
  set pendingSeekTarget(Duration? v) => _pendingVideoTarget = v;

  @Deprecated('pendingAlignTarget merged into pendingVideoTarget')
  Duration? get pendingAlignTarget => _pendingVideoTarget;
  @Deprecated('pendingAlignTarget merged into pendingVideoTarget')
  set pendingAlignTarget(Duration? v) => _pendingVideoTarget = v;

  // ================================================================
  // INTERNAL HELPERS (P2/P3: StartCue/Loop = â€œë²”ìœ„ ì •ë³´â€, seek = â€œììœ  ì‹œí‚¹â€)
  // ================================================================

  /// ë¹„ë””ì˜¤ë¥¼ ì˜¤ë””ì˜¤ seek íƒ€ê²Ÿì— ê°•ì œë¡œ ë§ì¶”ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì±„ë„.
  /// - EngineApiì—ì„œëŠ” "ëª©í‘œ ë“±ë¡"ë§Œ í•˜ê³ 
  /// - ì‹¤ì œ mpv.seekëŠ” VideoSyncService._tick()ì—ì„œë§Œ ìˆ˜í–‰í•œë‹¤.
  void _scheduleVideoSeek(Duration target) {
    _pendingVideoTarget = target;
  }

  /// ìœ íš¨ Loop ì—¬ë¶€ íŒë‹¨(ì—”ì§„ ê¸°ì¤€ ê¸€ë¡œë²Œ íƒ€ì„ë¼ì¸ í´ë¨í”„ í›„ A < Bì¸ì§€ í™•ì¸)
  bool _hasValidLoop(Duration? loopA, Duration? loopB) {
    if (loopA == null || loopB == null) return false;
    if (_duration <= Duration.zero) return false;
    final a = _clampToDuration(loopA);
    final b = _clampToDuration(loopB);
    return a < b;
  }

  /// P2/P3: StartCueëŠ” ì˜¤ì§ [0, duration]ë§Œ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”í•œë‹¤.
  /// - LoopA/BëŠ” í•˜í•œ/ìƒí•œìœ¼ë¡œ ê°œì…í•˜ì§€ ì•ŠëŠ”ë‹¤.
  /// - durationì´ ì•„ì§ 0ì´ë©´ ìŒìˆ˜ë§Œ 0ìœ¼ë¡œ ë§‰ê³  ê·¸ëŒ€ë¡œ ëŒë ¤ì¤€ë‹¤.
  Duration _normalizeStartCueValue(
    Duration sc, {
    Duration? loopA, // ì‹œê·¸ë‹ˆì²˜ ìœ ì§€ìš© (í˜„ì¬ëŠ” ë¬´ì‹œ)
    Duration? loopB, // ì‹œê·¸ë‹ˆì²˜ ìœ ì§€ìš© (í˜„ì¬ëŠ” ë¬´ì‹œ)
  }) {
    if (_duration <= Duration.zero) {
      return sc < Duration.zero ? Duration.zero : sc;
    }
    return _clampToDuration(sc);
  }

  /// P2/P3: seek íƒ€ê²Ÿì€ í•­ìƒ duration ê¸°ì¤€ ê¸€ë¡œë²Œ í´ë¨í”„ë§Œ ì ìš©í•œë‹¤.
  /// - StartCue/LoopëŠ” â€œë²”ìœ„ ì •ë³´â€ë¡œë§Œ ì¡´ì¬í•˜ê³ , ì‹¤ì œ ì‹œí‚¹ ê²½ë¡œì—ëŠ” ê°œì…í•˜ì§€ ì•ŠëŠ”ë‹¤.
  Duration _normalizeTargetForSeek(
    Duration target, {
    Duration? loopA, // í˜„ì¬ ë¬´ì‹œ
    Duration? loopB, // í˜„ì¬ ë¬´ì‹œ
    Duration? startCue, // í˜„ì¬ ë¬´ì‹œ
  }) {
    return _clampToDuration(target);
  }

    // ğŸ”¥ ì˜¤ë””ì˜¤(SoT) ê¸°ì¤€ íŠ¸ë™ ì¢…ë£Œ ì²˜ë¦¬ ê³µí†µ ë£¨í‹´
  Future<void> _handleTrackCompleted() async {
    try {
      // StartCueë¥¼ í•­ìƒ Screen ìƒíƒœì—ì„œ ê°€ì ¸ì˜¨ë‹¤.
      final raw = startCueProvider?.call() ?? Duration.zero;
      final cue = _normalizeStartCueValue(raw);

      _logSmpEngine(
        'trackCompleted: seek back to StartCue=${cue.inMilliseconds}ms '
        '(raw=${raw.inMilliseconds}ms) and auto play',
      );

      // StartCue ì •ë³´ë¥¼ ê°™ì´ ë„˜ê²¨ì„œ ì—”ì§„ ë‚´ë¶€ normalize ê·œì¹™ê³¼ë„ ì¼ì¹˜ì‹œí‚¨ë‹¤.
      await seekUnified(cue, startCue: cue);

      // âœ… P3 ê·œì¹™: Loop OFF + íŠ¸ë™ ë â†’ StartCueì—ì„œ ìë™ ì¬ìƒ ìœ ì§€
      await play();
    } catch (e) {
      debugPrint('[EngineApi] track-completed error: $e');
    }
  }

  // ================================================================
  // INIT
  // ================================================================
  Future<void> init() async {
    if (_initialized) return;
    _initialized = true;

    MediaKit.ensureInitialized();
    stInitEngine();
    _logSmpEngine('init(): engine initialized');

    // FFmpeg SoT polling (position stream)
    _positionTimer?.cancel();
    _positionTimer = Timer.periodic(const Duration(milliseconds: 50), (_) {
      if (!_hasFile) return;

      final raw = stGetPosition();
      final pos = (_duration > Duration.zero)
          ? _clampToDuration(raw)
          : raw; // duration ë¯¸ì •ì¼ ë•ŒëŠ” raw ê·¸ëŒ€ë¡œ

      // === ê¸°ë³¸ position ìŠ¤íŠ¸ë¦¼ ì „íŒŒ ===
      _positionCtl.add(pos);

      // === ì˜¤ë””ì˜¤(SoT) ê¸°ë°˜ íŠ¸ë™ ì¢…ë£Œ ê°ì§€ ===
      if (_duration > Duration.zero) {
        // "ë ê·¼ì²˜" ì˜ì—­ (ë§ˆì§€ë§‰ 80ms)
        final endThreshold = _duration - const Duration(milliseconds: 80);
        final wasAtEnd =
            _lastPolledPosition != null && _lastPolledPosition! >= endThreshold;
        final isAtEnd = pos >= endThreshold;

        // ë ì˜ì—­ì— ì§„ì… â†’ "í›„ë³´" í”Œë˜ê·¸
        if (!wasAtEnd && isAtEnd) {
          _endCandidate = true;
        }

        // í›„ë³´ ìƒíƒœì—ì„œ ìœ„ì¹˜ê°€ ë” ì´ìƒ ì•ˆ ì›€ì§ì´ê³ (ì •ì§€) ì˜¤ë””ì˜¤ëŠ” ì¬ìƒ ì¤‘ì´ë©´ â†’ ì‹¤ì œ ì¢…ë£Œë¡œ ê°„ì£¼
        if (_endCandidate &&
            _lastPolledPosition != null &&
            pos == _lastPolledPosition &&
            _nativePlaying) {
          _endCandidate = false;
          unawaited(_handleTrackCompleted());
        }
      }

      _lastPolledPosition = pos;

      // SoT ë¡œê¹… (500ms ì´ìƒ ê°„ê²©ìœ¼ë¡œë§Œ + tick ì±„ë„ì—ë§Œ)
      final now = DateTime.now();
      if (_lastPosLogAt == null ||
          now.difference(_lastPosLogAt!) >= const Duration(milliseconds: 500)) {
        _lastPosLogAt = now;
        _logSmpEngine(
          'tick: pos=${pos.inMilliseconds}ms, dur=${_duration.inMilliseconds}ms, playing=$_nativePlaying',
          tick: true,
        );
      }
    });

    // media_kit playing stream â†’ playing$ (ì˜ìƒ ìƒíƒœì™€ ì˜¤ë””ì˜¤ ìƒíƒœë¥¼ ìµœëŒ€í•œ ë§ì¶°ì¤€ë‹¤)
    _player.stream.playing.listen((v) {
      // ì˜¤ë””ì˜¤ëŠ” _nativePlaying ê¸°ì¤€ì´ì§€ë§Œ, UI í˜¸í™˜ì„±ì„ ìœ„í•´
      // ë¹„ë””ì˜¤ ì¬ìƒ ìƒíƒœë„ í•¨ê»˜ ë°˜ì˜í•œë‹¤.
      final combined = _nativePlaying || v;
      _playingCtl.add(combined);
      _logSmpEngine('player.stream.playing: mpvPlaying=$v, combined=$combined');
    });

    // ğŸ” ì˜ìƒ ì™„ë£Œ ì´ë²¤íŠ¸ëŠ” "ì˜¤ë””ì˜¤ ë§ˆìŠ¤í„°" ì›ì¹™ìƒ íŠ¸ë™ ì¢…ë£Œ ë¡œì§ì„ ì§ì ‘ ê±´ë“œë¦¬ì§€ ì•ŠëŠ”ë‹¤.
    _player.stream.completed.listen((_) {
      _logSmpEngine('player.stream.completed: video completed (audio=master)');
    });
  }

  // ================================================================
  // LOAD MEDIA (FFmpeg ë„¤ì´í‹°ë¸Œ ì—”ì§„ + optional video)
  // ================================================================
  Future<Duration> load({
    required String path,
    required void Function(Duration) onDuration,
  }) async {
    await init();

    final f = File(path);
    if (!await f.exists()) {
      throw Exception('[EngineApi] File not found: $path');
    }

    _logSmpEngine('load(): path=$path');

    // ì´ì „ íŒŒì¼ ì •ë¦¬
    stCloseFile();
    _hasFile = false;
    _duration = Duration.zero;
    _pendingVideoTarget = null;
    _nativePlaying = false;
    _playingCtl.add(false);
    _lastPolledPosition = null;
    _endCandidate = false;

    // ë„¤ì´í‹°ë¸Œ ì—”ì§„ì— íŒŒì¼ ì˜¤í”ˆ
    final ok = stOpenFile(path);
    if (!ok) {
      throw Exception(
        '[EngineApi] Failed to open file via native engine: $path',
      );
    }
    _hasFile = true;

    // FFmpeg duration í™•ë³´
    _duration = stGetDuration();
    if (_duration < Duration.zero) {
      _duration = Duration.zero;
    }


    onDuration(_duration);
    _durationCtl.add(_duration);

    // === Video path (audio disabled, keep-open) ===
    final lower = path.toLowerCase();
    final isVideo =
        lower.endsWith('.mp4') ||
        lower.endsWith('.mov') ||
        lower.endsWith('.mkv');

    if (isVideo) {
      await _player.open(
        Media(path, extras: {'audio': 'no', 'keep-open': 'yes'}),
        play: false,
      );
      await VideoSyncService.instance.attachPlayer(_player);
    }

    // ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ëª¨ë‘ 0ìœ¼ë¡œ ê°•ì œ align
    stSeekToDuration(Duration.zero);
    if (isVideo) {
      try {
        // ë¹„ë””ì˜¤ëŠ” VideoSyncService tickì—ì„œë§Œ seek ìˆ˜í–‰
        _scheduleVideoSeek(Duration.zero);
      } catch (e) {
        debugPrint('[EngineApi] load() initial align scheduling error: $e');
      }
    }

    _positionCtl.add(Duration.zero);

    _logSmpEngine(
      'load(): duration=${_duration.inMilliseconds}ms, isVideo=$isVideo',
    );

    return _duration;
  }

  // ================================================================
  // PLAYBACK CONTROL (ë„¤ì´í‹°ë¸Œ ì—”ì§„ + ë¹„ë””ì˜¤ ì—°ë™)
  // ================================================================
  Future<void> play() async {
    final cur = position;
    _logSmpEngine(
      'play() requested at pos=${cur.inMilliseconds}ms, nativePlaying=$_nativePlaying',
    );

    // ğŸ”’ ì´ë¯¸ ë„¤ì´í‹°ë¸Œ ì—”ì§„ì´ ì¬ìƒ ì¤‘ì´ë©´ ì ˆëŒ€ FFI í˜¸ì¶œí•˜ì§€ ì•ŠìŒ
    if (_nativePlaying) {
      _logSmpEngine(
        'play(): nativePlaying already true, skip stPlay() / _player.play()',
      );
      return;
    }

    try {
      // 1) FFmpeg / SoundTouch ë„¤ì´í‹°ë¸Œ ì—”ì§„ ì¬ìƒ ì‹œì‘
      stPlay();
      _nativePlaying = true;
    } catch (e) {
      debugPrint('[EngineApi] play() stPlay error: $e');
    }

    try {
      // 2) ì˜ìƒ í”Œë ˆì´ì–´(mpv) ì¬ìƒ ì‹œì‘ (ì˜ìƒ ì—†ìœ¼ë©´ ì˜ˆì™¸ ë¬´ì‹œ)
      await _player.play();
    } catch (_) {
      // ì˜ìƒì´ ì—†ìœ¼ë©´ ë¬´ì‹œ
    }

    // 3) ìƒìœ„ ë ˆì´ì–´ì— "ì§€ê¸ˆì€ ì¬ìƒ ì¤‘"ì´ë¼ê³  ë¸Œë¡œë“œìºìŠ¤íŠ¸
    _playingCtl.add(true);
    _logSmpEngine('play(): now nativePlaying=$_nativePlaying');
  }


  Future<void> pause() async {
    final cur = position;
    _logSmpEngine(
      'pause() requested at pos=${cur.inMilliseconds}ms, nativePlaying=$_nativePlaying',
    );

    // ë„¤ì´í‹°ë¸Œ ì—”ì§„ì— pause ì‹ í˜¸
    stPause();
    _nativePlaying = false;

    try {
      await _player.pause();
    } catch (_) {
      // ì˜ìƒì´ ì—†ìœ¼ë©´ ë¬´ì‹œ
    }

    _playingCtl.add(false);
    _logSmpEngine('pause(): now nativePlaying=$_nativePlaying');
  }

  Future<void> toggle() async {
    _logSmpEngine('toggle(): isPlaying=$isPlaying');
    if (isPlaying) {
      await pause();
    } else {
      await play();
    }
  }

  // ================================================================
  // Space Behavior
  //
  //  - ì¬ìƒ ì¤‘: pause()
  //  - ì •ì§€ ìƒíƒœ: StartCueë¡œ seek + play()
  //
  //  Loop ON/OFF, loopA/B ì¸ìëŠ” í˜„ì¬ëŠ” "ì°¸ê³  ì •ë³´"ë¡œë§Œ ì‚¬ìš©í•˜ê³ ,
  //  ì‹¤ì œ ë£¨í”„ ë™ì‘ì€ LoopExecutor ìª½ì—ì„œ ì²˜ë¦¬í•œë‹¤.
  // ================================================================
  Future<void> spaceBehavior(
    Duration startCue, {
    Duration? loopA,
    Duration? loopB,
    bool loopOn = false,
  }) async {
    if (!_hasFile) return;

    final cur = position;
    final dur = _duration;

    _logSmpEngine(
      'spaceBehavior() called with '
      'sc=${startCue.inMilliseconds}ms, '
      'cur=${cur.inMilliseconds}ms, '
      'dur=${dur.inMilliseconds}, '
      'isPlaying=$_nativePlaying, '
      'loopOn=$loopOn',
    );

    // ğŸ”º ì¬ìƒ ì¤‘ â†’ pause
    if (_nativePlaying) {
      await pause();
      return;
    }

    final cue = _normalizeStartCueValue(startCue, loopA: loopA, loopB: loopB);

    await seekUnified(cue, loopA: loopA, loopB: loopB, startCue: cue);

    await play();
  }


  // ================================================================
  // LOOP EXIT â†’ StartCue + Auto Play
  // ================================================================
  ///
  /// LoopExecutor ë“±ì—ì„œ ë§ˆì§€ë§‰ ë£¨í”„ ì¢…ë£Œ í›„ í˜¸ì¶œ:
  ///  - StartCueë¡œ seek
  ///  - ì¦‰ì‹œ play() ìœ ì§€ (Loop OFF + StartCue ì¬ìƒ ìœ ì§€)
  Future<void> loopExitToStartCue(
    Duration sc, {
    Duration? loopA,
    Duration? loopB,
  }) async {
    _logSmpEngine(
      'loopExitToStartCue(): sc=${sc.inMilliseconds}ms, '
      'loopA=${loopA?.inMilliseconds}, loopB=${loopB?.inMilliseconds}',
    );

    // P2/P3: StartCueëŠ” loop ë²”ìœ„ì™€ ë¬´ê´€í•˜ê²Œ [0, duration] ê¸°ì¤€ ì •ê·œí™”
    Duration cue = _normalizeStartCueValue(sc, loopA: loopA, loopB: loopB);

    _logSmpEngine(
      'loopExitToStartCue(): normalized cue=${cue.inMilliseconds}ms',
    );


    await seekUnified(cue, loopA: loopA, loopB: loopB, startCue: cue);
    // âœ… ì˜ë„: ë£¨í”„ ì¢…ë£Œ í›„ StartCueì—ì„œ ë°”ë¡œ ì¬ìƒ ìœ ì§€
    await play();
  }

  // ================================================================
  // TEMPO / PITCH / VOLUME (ë„¤ì´í‹°ë¸Œ ì—”ì§„ ì§ì ‘ í˜¸ì¶œ)
  // ================================================================
  Future<void> setTempo(double v) async {
    final clamped = v.clamp(0.5, 1.5);
    _logSmpEngine('setTempo(): v=$v â†’ clamped=$clamped');
    st_setTempo(clamped.toDouble());
  }

  Future<void> setPitch(int semi) async {
    final clamped = semi.clamp(-7, 7);
    _logSmpEngine('setPitch(): semi=$semi â†’ clamped=$clamped');
    st_setPitch(clamped.toDouble());
  }

  Future<void> setVolume(double v01) async {
    final clamped = v01.clamp(0.0, 1.5);
    _logSmpEngine('setVolume(): v01=$v01 â†’ clamped=$clamped');
    st_setVolume(clamped.toDouble());
  }

  Future<void> restoreChainState({
    required double tempo,
    required int pitchSemi,
    required double volume,
  }) async {
    _logSmpEngine(
      'restoreChainState(): tempo=$tempo, pitchSemi=$pitchSemi, volume=$volume',
    );
    await setTempo(tempo);
    await setPitch(pitchSemi);
    await setVolume(volume);
  }

  Future<void> tempo(double v) async => setTempo(v);
  Future<void> pitch(int semi) async => setPitch(semi);
  Future<void> volume(double v01) async => setVolume(v01);

  Future<void> restoreState({
    required double tempo,
    required int pitchSemi,
    required double volume,
  }) async {
    await restoreChainState(tempo: tempo, pitchSemi: pitchSemi, volume: volume);
  }

  // ================================================================
  // FAST-FORWARD / FAST-REVERSE (seek ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜)
  // ================================================================
  Timer? _ffrwTick;
  bool _ff = false;
  bool _fr = false;
  bool _ffStartedFromPause = false;
  bool _frStartedFromPause = false;

  static const Duration _ffrwInterval = Duration(milliseconds: 55);
  static const Duration _ffStep = Duration(milliseconds: 150);
  static const Duration _frStep = Duration(milliseconds: 150);

  Future<void> _startFfRwTick({
    required bool forward,
    required Duration startCue,
    Duration? loopA,
    Duration? loopB,
  }) async {
    final scNorm = _normalizeStartCueValue(
      startCue,
      loopA: loopA,
      loopB: loopB,
    );

    _logSmpEngine(
      '_startFfRwTick(): forward=$forward, startCue=${scNorm.inMilliseconds}ms, '
      'loopA=${loopA?.inMilliseconds}, loopB=${loopB?.inMilliseconds}',
    );

    _ffrwTick?.cancel();

    _ff = forward;
    _fr = !forward;

    _ffrwTick = Timer.periodic(_ffrwInterval, (_) async {
      if (!_ff && !_fr) return;
      if (_seeking) return;

      final cur = position;
      Duration next;

      if (_ff) {
        next = cur + _ffStep;
      } else {
        next = cur - _frStep;
      }

      // P2/P3: FF/FRì€ í•­ìƒ â€œíƒ€ì„ë¼ì¸ ììœ  ì´ë™â€
      // StartCue/LoopëŠ” ìƒí•˜í•œìœ¼ë¡œ ê°œì…í•˜ì§€ ì•Šê³ ,
      // duration ê¸°ë°˜ ê¸€ë¡œë²Œ í´ë¨í”„ë§Œ ì ìš©
      next = _clampToDuration(next);

      if (_seeking) return;

      _logSmpEngine(
        'FFRW tick: forward=$_ff, cur=${cur.inMilliseconds}ms â†’ next=${next.inMilliseconds}ms',
        tick: true,
      );

      await seekUnified(next);

      if (next == Duration.zero && _fr) {
        _logSmpEngine('FFRW tick: reached 0ms in FR â†’ stop', tick: true);
        await fastReverse(false, startCue: scNorm);
      }
      if (next == _duration && _ff) {
        _logSmpEngine(
          'FFRW tick: reached end(${_duration.inMilliseconds}ms) in FF â†’ stop',
          tick: true,
        );
        await fastForward(false, startCue: scNorm);
      }
    });
  }

  Future<void> fastForward(
    bool on, {
    required Duration startCue,
    Duration? loopA,
    Duration? loopB,
  }) async {
    final scNorm = _normalizeStartCueValue(
      startCue,
      loopA: loopA,
      loopB: loopB,
    );

    if (on) {
      _logSmpEngine(
        'fastForward(on): startCue=${scNorm.inMilliseconds}ms, '
        'loopA=${loopA?.inMilliseconds}, loopB=${loopB?.inMilliseconds}',
      );

      if (_ff) return;

      final wasPlaying = isPlaying;
      _ffStartedFromPause = !wasPlaying;

      if (!wasPlaying) {
        _logSmpEngine('fastForward(on): wasPaused â†’ seek to StartCue & play');
        await seekUnified(scNorm);
        await play();
      }

      _ff = true;
      _fr = false;

      await _startFfRwTick(
        forward: true,
        startCue: scNorm,
        loopA: loopA,
        loopB: loopB,
      );

      return;
    }

    if (!_ff) return;
    _ff = false;

    _logSmpEngine('fastForward(off): stop FFRW');

    _ffrwTick?.cancel();
    _ffrwTick = null;

    if (_ffStartedFromPause) {
      _logSmpEngine('fastForward(off): returning to pause()');
      await pause();
    }

    _ffStartedFromPause = false;
  }

  Future<void> fastReverse(
    bool on, {
    required Duration startCue,
    Duration? loopA,
    Duration? loopB,
  }) async {
    final scNorm = _normalizeStartCueValue(
      startCue,
      loopA: loopA,
      loopB: loopB,
    );

    if (on) {
      _logSmpEngine(
        'fastReverse(on): startCue=${scNorm.inMilliseconds}ms, '
        'loopA=${loopA?.inMilliseconds}, loopB=${loopB?.inMilliseconds}',
      );

      if (_fr) return;

      final wasPlaying = isPlaying;
      _frStartedFromPause = !wasPlaying;

      if (!wasPlaying) {
        _logSmpEngine('fastReverse(on): wasPaused â†’ seek to StartCue & play');
        await seekUnified(scNorm);
        await play();
      }

      _fr = true;
      _ff = false;

      await _startFfRwTick(
        forward: false,
        startCue: scNorm,
        loopA: loopA,
        loopB: loopB,
      );

      return;
    }

    if (!_fr) return;
    _fr = false;

    _logSmpEngine('fastReverse(off): stop FFRW');

    _ffrwTick?.cancel();
    _ffrwTick = null;

    if (_frStartedFromPause) {
      _logSmpEngine('fastReverse(off): returning to pause()');
      await pause();
    }

    _frStartedFromPause = false;
  }

  // ================================================================
  // UNIFIED SEEK (FFmpeg ë„¤ì´í‹°ë¸Œ ì—”ì§„ ê¸°ì¤€)
  // ================================================================
  Future<void> seekUnified(
    Duration d, {
    Duration? loopA,
    Duration? loopB,
    Duration? startCue,
  }) async {
    if (_seeking) {
      _logSmpEngine(
        'seekUnified(): already seeking, ignore new request d=${d.inMilliseconds}ms',
      );
      return;
    }

    if (_duration <= Duration.zero) {
      _logSmpEngine(
        'seekUnified(): duration is zero, ignore seek d=${d.inMilliseconds}ms',
      );
      return;
    }

    _seeking = true;

    final bool wasPlaying = isPlaying;

    // P2/P3: StartCue/LoopëŠ” ë²”ìœ„ ì •ì˜ ì „ìš©,
    //     ì‹¤ì œ seek íƒ€ê²Ÿì€ duration ê¸°ì¤€ ê¸€ë¡œë²Œ í´ë¨í”„ë§Œ ì ìš©
    final int origTargetMs = d.inMilliseconds;
    Duration target = _normalizeTargetForSeek(
      d,
      loopA: loopA,
      loopB: loopB,
      startCue: startCue,
    );

    _logSmpEngine(
      'seekUnified(): d=${d.inMilliseconds}ms, origTarget=$origTargetMs ms, '
      'loopA=${loopA?.inMilliseconds}, loopB=${loopB?.inMilliseconds}, '
      'startCue=${startCue?.inMilliseconds} â†’ finalTarget=${target.inMilliseconds}ms, '
      'wasPlaying=$wasPlaying',
    );

    // ë‚´ë¶€ ìƒíƒœ ìƒ posë¥¼ ë¨¼ì € ê°±ì‹  (SoT ê¸°ì¤€)
    _positionCtl.add(target);

    try {
      // 1) FFmpeg ë„¤ì´í‹°ë¸Œ ì—”ì§„ seek (ì˜¤ë””ì˜¤ ë§ˆìŠ¤í„°)
      stSeekToDuration(target);

      // 2) VideoSyncServiceì— ì•Œë¦¬ê¸° ìœ„í•œ pending target ì„¤ì •
      _scheduleVideoSeek(target);
    } catch (e) {
      debugPrint('[EngineApi] seekUnified error: $e');
    } finally {
      _seeking = false;
    }

    if (wasPlaying) {
      // ğŸ”’ ì¬ìƒ ì¤‘ì´ì—ˆëŠ”ë°, ì´ë¯¸ nativePlaying=trueë¼ë©´ ì¶”ê°€ resume ê¸ˆì§€
      if (!_nativePlaying) {
        _logSmpEngine('seekUnified(): resume play after seek');
        await play();
      } else {
        _logSmpEngine(
          'seekUnified(): already nativePlaying=true, skip resume play',
        );
      }
    } else {
      // ì˜¤ë””ì˜¤ëŠ” ì •ì§€ ìƒíƒœ ìœ ì§€, ì˜ìƒë„ ì •ì§€ ìƒíƒœë¡œ ë§ì¶°ì¤€ë‹¤.
      try {
        await _player.pause();
      } catch (_) {}
      _logSmpEngine('seekUnified(): keep paused after seek');
    }
  }


  // ================================================================
  // PUBLIC FFRW FACADE & HELPERS
  // ================================================================
  FfRwFacade get ffrw => FfRwFacade(this);

  /// StartCue ë²„íŠ¼ ì „ìš©:
  /// - Loop ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ StartCueì—ì„œ ë°”ë¡œ ì‹œì‘
  /// - Space í†µí•© ê·œì¹™(loopOnì— ë”°ë¥¸ ë¶„ê¸°)ì™€ ë…ë¦½ì ì¸ "ê°•ì œ StartCue ì¬ìƒ"
  Future<void> playFromStartCue(
    Duration sc, {
    Duration? loopA,
    Duration? loopB,
  }) async {
    Duration cue = _normalizeStartCueValue(sc, loopA: loopA, loopB: loopB);
    _logSmpEngine(
      'playFromStartCue(): sc=${sc.inMilliseconds}ms (norm=${cue.inMilliseconds}ms), '
      'loopA=${loopA?.inMilliseconds}, loopB=${loopB?.inMilliseconds}',
    );

    await seekUnified(cue, loopA: loopA, loopB: loopB, startCue: cue);
    await play();
  }

  // StickyVideoOverlay helper (Step 7ê¹Œì§€ ì„ì‹œ ìœ ì§€)
  Widget buildVideoOverlay({
    required ScrollController scrollController,
    required Size viewportSize,
    double collapseScrollPx = 480.0,
    double miniWidth = 360.0,
  }) {
    final vc = VideoSyncService.instance.controller;
    if (vc == null) return const SizedBox.shrink();

    return StickyVideoOverlay(
      controller: vc,
      scrollController: scrollController,
      viewportSize: viewportSize,
      collapseScrollPx: collapseScrollPx,
      miniWidth: miniWidth,
    );
  }

  // ================================================================
  // STOP & UNLOAD CURRENT MEDIA (for screen lifecycle)
  // ================================================================
  /// í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ë¥¼ ì™„ì „íˆ ì •ë¦¬í•œë‹¤.
  ///
  /// - FFRW íƒ€ì´ë¨¸/í”Œë˜ê·¸ ì •ì§€
  /// - ë„¤ì´í‹°ë¸Œ ì—”ì§„ pause + closeFile
  /// - mpv í”Œë ˆì´ì–´ pause + stop
  /// - duration/position/playing ìŠ¤íŠ¸ë¦¼ì„ 0/falseë¡œ ë¦¬ì…‹
  ///
  /// EngineApi ì‹±ê¸€í†¤ ìì²´ëŠ” ìœ ì§€í•˜ë˜,
  /// "ì§€ê¸ˆ ì¬ìƒ ì¤‘ì¸ íŠ¸ë™"ë§Œ ê¹¨ë—í•˜ê²Œ ì—†ì• ëŠ” ìš©ë„.
  Future<void> stopAndUnload() async {
    _logSmpEngine('stopAndUnload(): stopping playback & unloading media');

    // 1) FFRW ì •ë¦¬
    _ffrwTick?.cancel();
    _ffrwTick = null;
    _ff = false;
    _fr = false;
    _ffStartedFromPause = false;
    _frStartedFromPause = false;

    // 2) ë„¤ì´í‹°ë¸Œ ì—”ì§„ ì •ì§€
    try {
      stPause();
    } catch (_) {
      // ignore
    }

    if (_hasFile) {
      try {
        stCloseFile();
      } catch (_) {
        // ignore
      }
    }

    _hasFile = false;
    _nativePlaying = false;
    _pendingVideoTarget = null;
    _lastPolledPosition = null;
    _endCandidate = false;

    // 3) SoT / duration / playing ìƒíƒœ ë¦¬ì…‹
    _duration = Duration.zero;
    _durationCtl.add(_duration);
    _positionCtl.add(Duration.zero);
    _playingCtl.add(false);

    // 4) ë¹„ë””ì˜¤ ìª½ë„ ì •ì§€
    try {
      await _player.pause();
    } catch (_) {
      // ignore
    }
    try {
      await _player.stop();
    } catch (_) {
      // ignore
    }

    _logSmpEngine('stopAndUnload(): done (engine & video stopped)');
  }

  // ================================================================
  // CLEANUP
  // ================================================================
  Future<void> dispose() async {
    _logSmpEngine('dispose(): cleaning up engine & player');

    try {
      _ffrwTick?.cancel();
      _ffrwTick = null;
      _positionTimer?.cancel();
      _positionTimer = null;

      await VideoSyncService.instance.dispose();
      await _player.dispose();
    } catch (_) {}

    stCloseFile();
    stDisposeEngine();

    _hasFile = false;
    _nativePlaying = false;

    await _positionCtl.close();
    await _durationCtl.close();
    await _playingCtl.close();
  }

  // ================================================================
  // UTILS
  // ================================================================
  Duration _clamp(Duration v, Duration min, Duration max) {
    if (v < min) return min;
    if (v > max) return max;
    return v;
  }

  /// duration(SoT ì¶•) ê¸°ì¤€ ê¸€ë¡œë²Œ í´ë¨í”„
  Duration _clampToDuration(Duration v) {
    if (_duration <= Duration.zero) return Duration.zero;
    return _clamp(v, Duration.zero, _duration);
  }
}

// ================================================================
// PUBLIC FFRW FACADE (UI use)
// ================================================================
class FfRwFacade {
  final EngineApi api;
  FfRwFacade(this.api);

  Future<void> startForward({
    required Duration startCue,
    Duration? loopA,
    Duration? loopB,
    required bool loopOn,
  }) {
    return api.fastForward(
      true,
      startCue: startCue,
      loopA: loopOn ? loopA : null,
      loopB: loopOn ? loopB : null,
    );
  }

  Future<void> stopForward() => api.fastForward(false, startCue: Duration.zero);

  Future<void> startReverse({
    required Duration startCue,
    Duration? loopA,
    Duration? loopB,
    required bool loopOn,
  }) {
    return api.fastReverse(
      true,
      startCue: startCue,
      loopA: loopOn ? loopA : null,
      loopB: loopOn ? loopB : null,
    );
  }


  Future<void> stopReverse() => api.fastReverse(false, startCue: Duration.zero);
}
